{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Logistic Regression, and how does it differ from Linear\n",
        "Regression?\n",
        "\n",
        "Answer:Logistic Regression is a supervised machine learning algorithm used mainly for classification problems, especially binary classification where the output variable has two possible outcomes such as yes or no, true or false, or 0 and 1. Unlike Linear Regression, which predicts continuous numerical values, Logistic Regression predicts the probability that a given input belongs to a particular category. It uses the logistic or sigmoid function to map predicted values to a probability range between 0 and 1. The sigmoid function is expressed as 1 / (1 + e^(-z)), where z is the linear combination of input features and their corresponding weights. The output probability is then converted into a class label using a threshold, usually 0.5. In contrast, Linear Regression directly models the relationship between dependent and independent variables using a straight line and is used for predicting continuous outcomes. Logistic Regression also differs in terms of error measurement; it uses log loss or cross-entropy instead of mean squared error used in Linear Regression. Therefore, while Linear Regression is suitable for predicting numeric values, Logistic Regression is designed to classify data points into discrete categories based on probability estimates."
      ],
      "metadata": {
        "id": "Ggsa_vIchyFN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: Explain the role of the Sigmoid function in Logistic Regression.\n",
        "\n",
        "Answer:The Sigmoid function plays a crucial role in Logistic Regression as it transforms the output of the linear equation into a probability value that lies between 0 and 1. In Logistic Regression, the model first computes a linear combination of input features and their corresponding coefficients, represented as z = β₀ + β₁X₁ + β₂X₂ + ... + βnXn. This value of z can range from negative to positive infinity, which is not suitable for representing probabilities. The Sigmoid function, defined as 1 / (1 + e^(-z)), is then applied to this linear output to squash it into a range between 0 and 1. This transformation allows the model to interpret the result as the probability that a given input belongs to a particular class. For instance, if the output of the Sigmoid function is greater than or equal to 0.5, the data point is classified as belonging to class 1; otherwise, it is classified as class 0. Thus, the Sigmoid function acts as a bridge between the linear model and the probabilistic interpretation required for classification, enabling Logistic Regression to make meaningful predictions in terms of class probabilities."
      ],
      "metadata": {
        "id": "YAC3ypsXiOzN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: What is Regularization in Logistic Regression and why is it needed?\n",
        "\n",
        "Answer:Regularization in Logistic Regression is a technique used to prevent the model from overfitting the training data by adding a penalty term to the cost function. Overfitting occurs when a model learns the noise and random fluctuations in the training data instead of the true underlying patterns, which reduces its ability to generalize to new, unseen data. Regularization helps to control the complexity of the model by discouraging excessively large coefficient values. In Logistic Regression, two common types of regularization are used: L1 regularization (Lasso) and L2 regularization (Ridge). L1 regularization adds the absolute value of the coefficients as a penalty term to the cost function, which can shrink some coefficients to zero and effectively perform feature selection. L2 regularization, on the other hand, adds the squared magnitude of the coefficients as a penalty term, which helps to keep the coefficient values small but does not necessarily make them zero. By including these penalty terms, regularization ensures that the model remains simpler, more stable, and better at handling multicollinearity among features. Therefore, regularization is essential in Logistic Regression as it improves model generalization, enhances predictive performance, and prevents the model from fitting too closely to the training data."
      ],
      "metadata": {
        "id": "Q98VQu2qiVs9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: What are some common evaluation metrics for classification models, and\n",
        "why are they important?\n",
        "\n",
        "Answer:Evaluation metrics for classification models are essential because they help measure how well a model performs in distinguishing between different classes. Common evaluation metrics include accuracy, precision, recall, F1-score, and the area under the ROC curve (AUC-ROC). Accuracy represents the proportion of correctly predicted instances out of all predictions and is useful when the dataset is balanced. However, when dealing with imbalanced data, accuracy alone can be misleading because it may remain high even if the model performs poorly on the minority class. Precision measures the proportion of correctly predicted positive instances among all instances predicted as positive, indicating how reliable positive predictions are. Recall, also known as sensitivity or true positive rate, measures the proportion of actual positive cases that the model correctly identifies, showing how well the model captures positive instances. The F1-score is the harmonic mean of precision and recall, providing a single metric that balances both, especially useful when class distributions are uneven. The ROC curve and its corresponding AUC value measure the model’s ability to distinguish between classes across different threshold values, where a higher AUC indicates better classification performance. These metrics are important because they provide deeper insights into different aspects of model performance beyond simple accuracy, allowing data scientists to choose the most suitable model based on the problem’s specific requirements and class distribution.\n"
      ],
      "metadata": {
        "id": "lNH7YQpeidvl"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: Write a Python program that loads a CSV file into a Pandas DataFrame,\n",
        "splits into train/test sets, trains a Logistic Regression model, and prints its accuracy.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "I4Ol-_SRipUe"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADlcctfihp-C",
        "outputId": "eec9178a-b58f-491d-f388-b5189d015724"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First five rows of the dataset:\n",
            "   sepal length (cm)  sepal width (cm)  petal length (cm)  petal width (cm)  \\\n",
            "0                5.1               3.5                1.4               0.2   \n",
            "1                4.9               3.0                1.4               0.2   \n",
            "2                4.7               3.2                1.3               0.2   \n",
            "3                4.6               3.1                1.5               0.2   \n",
            "4                5.0               3.6                1.4               0.2   \n",
            "\n",
            "   target  \n",
            "0       0  \n",
            "1       0  \n",
            "2       0  \n",
            "3       0  \n",
            "4       0  \n",
            "\n",
            "Logistic Regression Model Accuracy: 100.00%\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "print(\"First five rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"\\nLogistic Regression Model Accuracy: {:.2f}%\".format(accuracy * 100))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to train a Logistic Regression model using L2\n",
        "regularization (Ridge) and print the model coefficients and accuracy.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "kiIdLvi3i_dZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "df['target'] = iris.target\n",
        "\n",
        "X = df.iloc[:, :-1]\n",
        "y = df['target']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = LogisticRegression(penalty='l2', solver='lbfgs', max_iter=200)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Model Coefficients:\")\n",
        "print(model.coef_)\n",
        "print(\"\\nIntercept:\")\n",
        "print(model.intercept_)\n",
        "print(\"\\nLogistic Regression Model Accuracy: {:.2f}%\".format(accuracy * 100))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xe_OEOvOjD2A",
        "outputId": "62e076b6-e94f-462a-d8da-e6cf3e7bc81f"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Coefficients:\n",
            "[[-0.39345607  0.96251768 -2.37512436 -0.99874594]\n",
            " [ 0.50843279 -0.25482714 -0.21301129 -0.77574766]\n",
            " [-0.11497673 -0.70769055  2.58813565  1.7744936 ]]\n",
            "\n",
            "Intercept:\n",
            "[  9.00884295   1.86902164 -10.87786459]\n",
            "\n",
            "Logistic Regression Model Accuracy: 100.00%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to train a Logistic Regression model for multiclass\n",
        "classification using multi_class='ovr' and print the classification report.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "ExG4sevvjLDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "model = OneVsRestClassifier(LogisticRegression(solver='liblinear', max_iter=200))\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print(classification_report(y_test, y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK1eO0-RjObc",
        "outputId": "ce17604d-2ecc-4788-a43a-dcad870cdd22"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        19\n",
            "           1       1.00      0.92      0.96        13\n",
            "           2       0.93      1.00      0.96        13\n",
            "\n",
            "    accuracy                           0.98        45\n",
            "   macro avg       0.98      0.97      0.97        45\n",
            "weighted avg       0.98      0.98      0.98        45\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to apply GridSearchCV to tune C and penalty\n",
        "hyperparameters for Logistic Regression and print the best parameters and validation\n",
        "accuracy.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:\n"
      ],
      "metadata": {
        "id": "TU5oWw41jmN8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "param_grid = {\n",
        "    'estimator__C': [0.01, 0.1, 1, 10, 100],\n",
        "    'estimator__penalty': ['l1', 'l2']\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(OneVsRestClassifier(LogisticRegression(solver='liblinear', max_iter=1000)), param_grid, cv=5)\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Parameters:\", grid.best_params_)\n",
        "print(\"Validation Accuracy:\", grid.best_score_)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1SON_6qjr28",
        "outputId": "0a5e6772-3a6e-4dee-a945-a9b81966730a"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'estimator__C': 10, 'estimator__penalty': 'l2'}\n",
            "Validation Accuracy: 0.9523809523809523\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to standardize the features before training Logistic\n",
        "Regression and compare the model's accuracy with and without scaling.\n",
        "\n",
        "(Use Dataset from sklearn package)\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:\n"
      ],
      "metadata": {
        "id": "nAbHymLCkBYk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "iris = load_iris()\n",
        "X = iris.data\n",
        "y = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "\n",
        "model1 = LogisticRegression(max_iter=200)\n",
        "model1.fit(X_train, y_train)\n",
        "y_pred1 = model1.predict(X_test)\n",
        "acc_without_scaling = accuracy_score(y_test, y_pred1)\n",
        "\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "model2 = LogisticRegression(max_iter=200)\n",
        "model2.fit(X_train_scaled, y_train)\n",
        "y_pred2 = model2.predict(X_test_scaled)\n",
        "acc_with_scaling = accuracy_score(y_test, y_pred2)\n",
        "\n",
        "print(\"Accuracy without scaling:\", acc_without_scaling)\n",
        "print(\"Accuracy with scaling:\", acc_with_scaling)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6m2u0YKhkEeN",
        "outputId": "1a876cf5-b3db-421e-85c9-6039c8c47713"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy without scaling: 1.0\n",
            "Accuracy with scaling: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: Imagine you are working at an e-commerce company that wants to\n",
        "predict which customers will respond to a marketing campaign. Given an imbalanced\n",
        "dataset (only 5% of customers respond), describe the approach you’d take to build a\n",
        "Logistic Regression model — including data handling, feature scaling, balancing\n",
        "classes, hyperparameter tuning, and evaluating the model for this real-world business\n",
        "use case.\n",
        "\n",
        "Answer:For an imbalanced marketing campaign dataset where only 5% of customers respond, I would start by collecting and cleaning relevant data, including customer demographics, purchase history, and engagement metrics, while handling missing values and removing duplicates. I would perform feature engineering to create meaningful variables, such as recency, frequency, monetary (RFM) scores, and one-hot encode categorical features. Numeric features would be standardized using methods like `StandardScaler` to ensure proper convergence of the Logistic Regression model. To address the severe class imbalance, I would either use resampling techniques such as SMOTE to oversample the minority class or undersample the majority class, or set `class_weight='balanced'` in the Logistic Regression model. Hyperparameter tuning would be performed using GridSearchCV or RandomizedSearchCV to optimize parameters like the regularization strength `C`, penalty type (`l1` or `l2`), solver, and class weighting. For model evaluation, I would avoid relying on accuracy and instead focus on metrics suitable for imbalanced data, such as precision, recall, F1-score, ROC-AUC, and precision-recall curves, emphasizing the recall for responders since identifying them is the business priority. Finally, the model would be validated using stratified splits or cross-validation, and deployed in a way that allows monitoring for drift and regular retraining with new campaign data, ensuring it remains aligned with business objectives and maximizes campaign effectiveness.\n",
        "\n"
      ],
      "metadata": {
        "id": "lRGjrqf8kbiP"
      }
    }
  ]
}