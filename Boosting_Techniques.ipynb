{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Boosting Techniques"
      ],
      "metadata": {
        "id": "Q2DhCl8edFlZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 1: What is Boosting in Machine Learning? Explain how it improves weak\n",
        "learners.\n",
        "\n",
        "Answer:Boosting in machine learning is an ensemble technique that combines multiple weak learners to form a strong predictive model. A weak learner is a model that performs slightly better than random guessing, such as a shallow decision tree. Boosting works by training these weak learners sequentially, where each new learner focuses more on the data points that previous models misclassified. During this process, the algorithm assigns higher weights to the incorrectly predicted instances, forcing the next learner to pay more attention to them. As more learners are added, their outputs are combined—usually through a weighted majority vote in classification or weighted sum in regression—to create a final strong model. This iterative process reduces bias and variance, improving the model’s accuracy and generalization. Popular boosting algorithms include AdaBoost, Gradient Boosting, and XGBoost, all of which refine the learning process to enhance the overall performance of weak learners.\n"
      ],
      "metadata": {
        "id": "_xM8vCUHdHwD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 2: What is the difference between AdaBoost and Gradient Boosting in terms\n",
        "of how models are trained?\n",
        "\n",
        "Answer:The main difference between AdaBoost and Gradient Boosting lies in how they train their models and handle errors. AdaBoost, short for Adaptive Boosting, works by adjusting the weights of training examples based on how well previous models performed. It assigns higher weights to misclassified instances so that subsequent weak learners focus more on those difficult cases. Each learner is trained independently but sequentially, with its contribution weighted based on accuracy. In contrast, Gradient Boosting uses a more mathematical approach by training learners to minimize the residual errors of the previous model through gradient descent optimization. Instead of reweighting data points like AdaBoost, it fits the new learner to the negative gradient of the loss function, which represents the direction of steepest error reduction. Essentially, AdaBoost modifies sample weights to focus on difficult data points, while Gradient Boosting minimizes a differentiable loss function directly through gradient-based optimization, making it more flexible and powerful for complex tasks.\n"
      ],
      "metadata": {
        "id": "5Wus1CJZdZZm"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 3: How does regularization help in XGBoost?\n",
        "\n",
        "Answer:Regularization in XGBoost helps prevent overfitting and improves the generalization of the model by adding penalty terms to the objective function. Unlike traditional boosting methods, XGBoost includes both L1 (Lasso) and L2 (Ridge) regularization terms that control the complexity of the model by penalizing large weights in the trees. This means that if a model becomes too complex or tries to fit noise in the data, the regularization terms will discourage it by increasing the overall loss, thereby promoting simpler and more robust models. Regularization helps XGBoost strike a balance between model accuracy and complexity, ensuring it performs well not only on training data but also on unseen test data. Additionally, it helps improve the stability of the learning process, reduces variance, and enhances computational efficiency by pruning unnecessary splits in the decision trees.\n"
      ],
      "metadata": {
        "id": "0mmhD6RndhHp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 4: Why is CatBoost considered efficient for handling categorical data?\n",
        "\n",
        "Answer:CatBoost is considered highly efficient for handling categorical data because it incorporates a unique algorithm that converts categorical features into numerical values without the need for extensive preprocessing like one-hot encoding or label encoding. Instead, CatBoost uses a technique called “ordered target statistics,” where it replaces categorical values with combinations of target-based statistics calculated in an ordered and randomized manner to prevent target leakage. This approach allows the model to effectively capture the relationship between categorical features and the target variable while maintaining generalization. Additionally, CatBoost automatically handles high-cardinality categorical features and can efficiently process them even when the number of categories is large. Its built-in support for categorical data also simplifies the data preparation process and reduces training time, making it more efficient and less prone to overfitting compared to other boosting algorithms that require manual encoding.\n",
        "\n"
      ],
      "metadata": {
        "id": "_BA8tiRXd6R3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 5: What are some real-world applications where boosting techniques are\n",
        "preferred over bagging methods?\n",
        "\n",
        "Answer:Boosting techniques are preferred over bagging methods in real-world applications where achieving high predictive accuracy and handling complex patterns in data are crucial. For example, in finance, boosting algorithms like XGBoost and LightGBM are widely used for credit scoring, fraud detection, and risk assessment because they can capture subtle nonlinear relationships and interactions between variables. In healthcare, boosting is applied for disease prediction and medical image analysis, as it effectively identifies intricate patterns in patient data. In e-commerce and marketing, boosting models are favored for customer churn prediction, recommendation systems, and sales forecasting due to their ability to improve precision through iterative learning. Additionally, in fields like natural language processing and computer vision, boosting helps enhance model performance in sentiment analysis, spam detection, and image classification tasks. Overall, boosting is preferred when the goal is to maximize accuracy and performance, especially in structured or tabular data scenarios where weak learners can be combined to form a highly accurate and robust predictive model.\n"
      ],
      "metadata": {
        "id": "dqLPqGPOeA6c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 6: Write a Python program to:\n",
        "\n",
        "● Train an AdaBoost Classifier on the Breast Cancer dataset\n",
        "\n",
        "● Print the model accuracy\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "JauUfE4heHj5"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UaYtpttOdEhS",
        "outputId": "471b1ee5-7599-4749-8313-67cba3fa963f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "AdaBoost Classifier Accuracy: 0.9736842105263158\n"
          ]
        }
      ],
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = AdaBoostClassifier(n_estimators=100, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"AdaBoost Classifier Accuracy:\", accuracy)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 7: Write a Python program to:\n",
        "\n",
        "● Train a Gradient Boosting Regressor on the California Housing dataset\n",
        "\n",
        "● Evaluate performance using R-squared score\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:"
      ],
      "metadata": {
        "id": "CaKKCUZNeZQr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import GradientBoostingRegressor\n",
        "from sklearn.metrics import r2_score\n",
        "\n",
        "data = fetch_california_housing()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = GradientBoostingRegressor(n_estimators=100, learning_rate=0.1, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "r2 = r2_score(y_test, y_pred)\n",
        "print(\"Gradient Boosting Regressor R-squared Score:\", r2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ugqq2KzfeeFO",
        "outputId": "9ae64750-18e3-48e6-a73c-b2da4f0f3e15"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gradient Boosting Regressor R-squared Score: 0.7756446042829697\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 8: Write a Python program to:\n",
        "\n",
        "● Train an XGBoost Classifier on the Breast Cancer dataset\n",
        "\n",
        "● Tune the learning rate using GridSearchCV\n",
        "\n",
        "● Print the best parameters and accuracy\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:\n"
      ],
      "metadata": {
        "id": "we44OMOkejm4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "param_grid = {'learning_rate': [0.01, 0.05, 0.1, 0.2, 0.3]}\n",
        "model = XGBClassifier(eval_metric='logloss', random_state=42)\n",
        "\n",
        "grid_search = GridSearchCV(estimator=model, param_grid=param_grid, cv=3, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "best_model = grid_search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"XGBoost Classifier Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xOpbGB6NerSu",
        "outputId": "2465ec15-6b31-4b8a-fe07-541cdf7be368"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.1}\n",
            "XGBoost Classifier Accuracy: 0.956140350877193\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 9: Write a Python program to:\n",
        "\n",
        "● Train a CatBoost Classifier\n",
        "\n",
        "● Plot the confusion matrix using seaborn\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:\n"
      ],
      "metadata": {
        "id": "bOZDOhO2e4iS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "model = CatBoostClassifier(verbose=0, random_state=42)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "plt.figure(figsize=(5,4))\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Malignant', 'Benign'], yticklabels=['Malignant', 'Benign'])\n",
        "plt.title(\"CatBoost Classifier Confusion Matrix\")\n",
        "plt.xlabel(\"Predicted\")\n",
        "plt.ylabel(\"Actual\")\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 410
        },
        "id": "Ic3OYNIJe9E5",
        "outputId": "efcc982f-4611-4065-b8fc-f4606e2aefc2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 500x400 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Question 10: You're working for a FinTech company trying to predict loan default using\n",
        "customer demographics and transaction behavior.\n",
        "\n",
        "The dataset is imbalanced, contains missing values, and has both numeric and\n",
        "categorical features.\n",
        "\n",
        "Describe your step-by-step data science pipeline using boosting techniques:\n",
        "\n",
        "● Data preprocessing & handling missing/categorical values\n",
        "\n",
        "● Choice between AdaBoost, XGBoost, or CatBoost\n",
        "\n",
        "● Hyperparameter tuning strategy\n",
        "\n",
        "● Evaluation metrics you'd choose and why\n",
        "\n",
        "● How the business would benefit from your model\n",
        "\n",
        "(Include your Python code and output in the code box below.)\n",
        "\n",
        "Answer:For a production-ready boosting pipeline for predicting loan default on an imbalanced, mixed-type dataset, I would first perform careful preprocessing: load the data, inspect and impute missing values using context-aware strategies (median/imputation for numeric features with `SimpleImputer` or iterative imputation when relationships matter, and frequency/most-frequent or target-/CatBoost-style statistics for categorical features), create simple engineered features from transaction histories (e.g., rolling averages, counts, time-since-last-activity), transform skewed numerics (log or rank transforms where appropriate), and encode categorical features only when required (prefer native categorical handling by the learner to avoid harmful one-hot expansion); I would also handle class imbalance by combining algorithm-level methods and data-level methods — first try algorithmic approaches such as scale_pos_weight (XGBoost), `class_weight` alternatives or CatBoost’s `auto_class_weights`, and experiment with careful resampling (SMOTE or focused undersampling) inside cross-validation folds to avoid leakage. For the model choice, I would prefer CatBoost as the first candidate because it natively and robustly handles categorical features and ordered target statistics that reduce target leakage and it tolerates some missingness; if inference speed or distributed training matters I’d trial LightGBM/XGBoost next and ensure proper categorical handling (or use target encoding with rigorous CV schemes). My hyperparameter tuning strategy would use a staged search: begin with a small randomized search across broad ranges for learning_rate, n_estimators, max_depth, l2_leaf_reg (or reg_lambda), and subsample/colsample parameters to find good regions, then refine with Bayesian optimization or a focused GridSearchCV on the most sensitive hyperparameters (using stratified grouped cross-validation if there are temporal or customer-group correlations), always using pipelines and `scikit-learn`’s `StratifiedKFold` to avoid leakage and ensuring resampling is done inside folds; I would also include early_stopping rounds based on a validation fold to prevent overfitting. For evaluation I would prioritize metrics appropriate for imbalanced classification: area under the precision–recall curve (PR-AUC) and ROC-AUC as primary discrimination metrics, but emphasize precision@k (business-relevant top-k default capture), recall (to avoid missing risky customers), F1 for balance, and calibration metrics (Brier score, reliability plots) because predicted probabilities drive risk-based decisions; I would report confusion-matrix-derived business metrics (false positive cost vs false negative cost) and use cost-sensitive evaluation (expected monetary loss) so model selection reflects real business impact rather than raw accuracy. The business benefits would be concrete: improved default detection (higher recall at an acceptable precision) reduces loan losses and enables smarter credit limits and targeted interventions, calibrated probabilities enable risk-based pricing and dynamic reserve allocations, and using explainable boosting (SHAP values) helps compliance and provides feature insights for product and underwriting teams to reduce future risk. Example minimal runnable code (concise) to illustrate the approach: from sklearn.model_selection import train_test_split, StratifiedKFold, RandomizedSearchCV; from sklearn.impute import SimpleImputer; from catboost import CatBoostClassifier; from sklearn.metrics import average_precision_score, roc_auc_score, precision_recall_curve; X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42); imputer = SimpleImputer(strategy='median'); X_train = imputer.fit_transform(X_train); X_test = imputer.transform(X_test); model = CatBoostClassifier(loss_function='Logloss', eval_metric='AUC', random_seed=42, verbose=0, auto_class_weights='Balanced'); param_dist = {'learning_rate':[0.01,0.03,0.05,0.1],'depth':[4,6,8],'l2_leaf_reg':[1,3,5],'iterations':[200,500]}; rs = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=12, scoring='average_precision', cv=StratifiedKFold(n_splits=3), n_jobs=-1, random_state=42); rs.fit(X_train, y_train); best = rs.best_estimator_; proba = best.predict_proba(X_test)[:,1]; print('PR-AUC:', average_precision_score(y_test, proba), 'ROC-AUC:', roc_auc_score(y_test, proba), 'Best params:', rs.best_params_). Expected output (example): PR-AUC ~0.35–0.6 and ROC-AUC ~0.75–0.90 depending on data quality, with `rs.best_params_` printed; these numeric ranges will vary by dataset and feature engineering.\n"
      ],
      "metadata": {
        "id": "WYSvRwmPfQuC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.impute import SimpleImputer\n",
        "from catboost import CatBoostClassifier\n",
        "from sklearn.metrics import roc_auc_score, classification_report\n",
        "from sklearn.datasets import make_classification\n",
        "\n",
        "X, y = make_classification(n_samples=1000, n_features=10, weights=[0.8, 0.2], random_state=42)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
        "\n",
        "imputer = SimpleImputer(strategy='median')\n",
        "X_train = imputer.fit_transform(X_train)\n",
        "X_test = imputer.transform(X_test)\n",
        "\n",
        "model = CatBoostClassifier(verbose=0, auto_class_weights='Balanced', random_state=42)\n",
        "param_dist = {'learning_rate': [0.01, 0.05, 0.1], 'depth': [4, 6, 8], 'l2_leaf_reg': [1, 3, 5], 'iterations': [200, 500]}\n",
        "\n",
        "search = RandomizedSearchCV(model, param_distributions=param_dist, n_iter=5, scoring='roc_auc', cv=3, random_state=42)\n",
        "search.fit(X_train, y_train)\n",
        "\n",
        "best_model = search.best_estimator_\n",
        "y_pred = best_model.predict(X_test)\n",
        "roc = roc_auc_score(y_test, y_pred)\n",
        "\n",
        "print(\"Best Parameters:\", search.best_params_)\n",
        "print(\"ROC-AUC Score:\", roc)\n",
        "print(classification_report(y_test, y_pred))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jh-trz5RfmGE",
        "outputId": "213fb6eb-4548-41df-eb5d-a867dd9a8448"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'learning_rate': 0.1, 'l2_leaf_reg': 5, 'iterations': 200, 'depth': 8}\n",
            "ROC-AUC Score: 0.8745206319987728\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.97      0.96       159\n",
            "           1       0.86      0.78      0.82        41\n",
            "\n",
            "    accuracy                           0.93       200\n",
            "   macro avg       0.90      0.87      0.89       200\n",
            "weighted avg       0.93      0.93      0.93       200\n",
            "\n"
          ]
        }
      ]
    }
  ]
}